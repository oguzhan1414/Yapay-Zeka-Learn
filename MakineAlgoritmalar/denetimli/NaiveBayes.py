import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix

# 1. VERÄ° SETÄ° (Senaryo: Gelen Mesajlar)
# Spam ve Normal (Ham) mesajlar karÄ±ÅŸÄ±k
data = {
    'Mesaj': [
        "Tebrikler bedava tatil kazandÄ±nÄ±z hemen tÄ±klayÄ±n",  # SPAM
        "BugÃ¼n dersten sonra buluÅŸalÄ±m mÄ±?",  # NORMAL
        "Fatura Ã¶demeniz gecikmiÅŸtir lÃ¼tfen arayÄ±n",  # SPAM (olabilir)
        "YarÄ±nki toplantÄ± saat 10:00'da unutma",  # NORMAL
        "Ã–zel kampanya! %50 indirim ÅŸansÄ± seni bekliyor",  # SPAM
        "AkÅŸama eve gelirken ekmek alÄ±r mÄ±sÄ±n?",  # NORMAL
        "Acil nakit ihtiyacÄ±nÄ±z iÃ§in hemen baÅŸvurun",  # SPAM
        "Proje dosyasÄ±nÄ± mail attÄ±m kontrol eder misin?",  # NORMAL
        "SÄ±nÄ±rlÄ± sÃ¼re iÃ§in bÃ¼yÃ¼k fÄ±rsat kaÃ§Ä±rma",  # SPAM
        "Hafta sonu sinemaya gidelim mi?"  # NORMAL
    ],
    'Etiket': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1: SPAM, 0: NORMAL
}

df = pd.DataFrame(data)

# 2. VERÄ°YÄ° SAYISALLAÅTIRMA (Bag of Words)
# Bilgisayar "tatil" kelimesini anlamaz, "tatil"in geÃ§tiÄŸi sÄ±klÄ±ÄŸÄ± anlar.
# CountVectorizer, kelimeleri sayar ve bir matrise dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['Mesaj'])  # MesajlarÄ± sayÄ±sal vektÃ¶rlere Ã§evir
y = df['Etiket']

# X'in neye benzediÄŸini anlamak iÃ§in (Kelime Havuzu)
# print(vectorizer.get_feature_names_out()) # Kelime listesini gÃ¶rmek istersen aÃ§abilirsin

# 3. EÄÄ°TÄ°M VE TEST AYRIMI
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. MODEL KURULUMU
# Metin verileri iÃ§in genelde 'MultinomialNB' kullanÄ±lÄ±r.
model = MultinomialNB()
model.fit(X_train, y_train)

# 5. TAHMÄ°N VE DEÄERLENDÄ°RME
y_pred = model.predict(X_test)

print(f"Model DoÄŸruluÄŸu: %{accuracy_score(y_test, y_pred) * 100:.2f}")

# 6. GÃ–RSELLEÅTÄ°RME (Spam OlasÄ±lÄ±klarÄ±)
# Modelin hangi kelimeleri 'Spam' olarak iÅŸaretlediÄŸini anlamak iÃ§in
# Basit bir Confusion Matrix Ã§izelim
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=['Normal', 'Spam'], yticklabels=['Normal', 'Spam'])
plt.title('Spam Filtresi BaÅŸarÄ±sÄ±')
plt.xlabel('Tahmin Edilen')
plt.ylabel('GerÃ§ek Durum')
plt.show()

# 7. Ä°NTERAKTÄ°F SPAM KONTROL ROBOTU
print("\n--- SPAM KONTROL SÄ°STEMÄ° ---")
print("Bir mesaj yazÄ±n, spam olup olmadÄ±ÄŸÄ±nÄ± sÃ¶yleyeyim.")

while True:
    user_input = input("\nMesajÄ±nÄ±z (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): ")
    if user_input.lower() == 'q':
        break

    # DÄ°KKAT: KullanÄ±cÄ±nÄ±n girdiÄŸi metni de modelin anladÄ±ÄŸÄ± dile (vektÃ¶re) Ã§evirmeliyiz!
    # Burada 'transform' kullanÄ±yoruz, 'fit' deÄŸil. Ã‡Ã¼nkÃ¼ model kelimeleri zaten Ã¶ÄŸrendi.
    input_vector = vectorizer.transform([user_input])

    tahmin = model.predict(input_vector)[0]
    olasilik = model.predict_proba(input_vector)[0]  # [Normal OlasÄ±lÄ±ÄŸÄ±, Spam OlasÄ±lÄ±ÄŸÄ±]

    if tahmin == 1:
        print(f"ğŸš« UYARI: Bu mesaj **SPAM** olabilir! (Spam Ä°htimali: %{olasilik[1] * 100:.1f})")
    else:
        print(f"âœ… GÃœVENLÄ°: Bu normal bir mesaj. (GÃ¼venli Ä°htimali: %{olasilik[0] * 100:.1f})")